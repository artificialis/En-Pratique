{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c002c9-cb35-40ce-8891-e36e78b36879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e60d2-898f-4810-88a2-f9db66d57f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ecd2e-4bd5-44ca-a460-815851cf7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PretrainedSpeakerEmbedding(\n",
    "    \"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "    device=torch.device(\"cuda\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b404a88-a12e-48ee-891b-f9a82c962a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Audio\n",
    "from pyannote.core import Segment\n",
    "audio = Audio(sample_rate=16000, mono=\"downmix\")\n",
    "\n",
    "# SPEAKER 01 - 1\n",
    "\n",
    "# Start end\n",
    "s1_seg_start = 0.03096875\n",
    "s1_seg_end = 22.035968750000002\n",
    "\n",
    "# extract embedding for a speaker speaking between t=3s and t=6s\n",
    "speaker1 = Segment(s1_seg_start, s1_seg_end)\n",
    "waveform1, sample_rate1 = audio.crop(\"audio/speaker_02.wav\", speaker1)\n",
    "embedding1 = model(waveform1[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214fdda-78be-422d-8964-0a01fa8b724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start end\n",
    "s2_seg_start = 24.44909375\n",
    "s2_seg_end = 31.97534375\n",
    "\n",
    "# SPEAKER 00\n",
    "\n",
    "# extract embedding for a speaker speaking between t=7s and t=12s\n",
    "speaker2 = Segment(s2_seg_start, s2_seg_end)\n",
    "waveform2, sample_rate2 = audio.crop(\"audio/speaker_02.wav\", speaker2)\n",
    "embedding2 = model(waveform2[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a3e09-c871-46e1-91a9-6e050d6d3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start end\n",
    "s3_seg_start = 35.89034375\n",
    "s3_seg_end = 63.37971875\n",
    "\n",
    "# SPEAKER 01 - 2\n",
    "\n",
    "# extract embedding for a speaker speaking between t=7s and t=12s\n",
    "speaker3 = Segment(s3_seg_start, s3_seg_end)\n",
    "waveform3, sample_rate3 = audio.crop(\"audio/speaker_02.wav\", speaker3)\n",
    "embedding3 = model(waveform3[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aac987-d2fa-484a-bb3a-1c250e822d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare embeddings using \"cosine\" distance\n",
    "from scipy.spatial.distance import cdist\n",
    "distance1 = cdist(embedding1, embedding2, metric=\"cosine\")\n",
    "distance2 = cdist(embedding1, embedding3, metric=\"cosine\")\n",
    "distance3 = cdist(embedding2, embedding3, metric=\"cosine\")\n",
    "print(f\"Distance Speaker 01/1 - Speaker 00: {distance1}\")\n",
    "print(f\"Distance Speaker 01/1 - Speaker 01/2: {distance2}\")\n",
    "print(f\"Distance Speaker 00 - Speaker 01/2: {distance3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a10d1c-13fd-4833-84f5-101ff9e94f8a",
   "metadata": {},
   "outputs": [],
   "source": "embedding3.shape\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ecf4b7-5a98-4435-8834-5caf11a9f1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
